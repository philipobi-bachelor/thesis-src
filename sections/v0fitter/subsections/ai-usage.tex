From the models available in GitHub Copilot, I selected the following for comparison\footnote{%
  See Section \ref{sec:model-selection} for model details and selection rationale
}:
\begin{itemize}
  \item Anthropic's Claude Sonnet 4 \cite{claude-sonnet4}
  \item Gemini 2.5 Pro by Google \cite{gemini25pro}
  \item OpenAI o4-mini \cite{o4mini}
  \item OpenAI's GPT-4o \cite{gpt-4o}
\end{itemize}

\paragraph{Note:}
Each of the following three sections summarizes key findings from testing the models' capabilities on a task related to the V0Fitter refactoring process.
For further details, such as metaprompts and complete chat logs \textemdash\ including the exact prompts, model responses and any generated code edits%
\footnote{Cf.\ \enquote{Squashed changes} section at the end of the chat logs}
\textemdash\ please refer to the corresponding subdirectory of the chat archive repository%
\footnote{\repoRef{chats}{chats}}.
A link to the relevant subdirectory is provided in the footnote of each section heading.

\def\sectitle{Refactoring advice}
\subsubsection[\sectitle]%
{\sectitle
  \footnote{\repoRef{chats/tree/main/v0fitter/refactoring-advice}{chats/v0fitter/refactoring-advice}}
}\label{sec:refactoring-advice}
Before beginning with the refactoring of the V0Fitter, I prompted the models for general refactoring advice.
I provided all models with the same prompt and included the V0Fitter source code%
\footnote{Basf2 repository at commit release-09-00-00}
as context, using the Ask mode in VS Code's Copilot Chat panel.

Overall, the responses demonstrated a reasonable comprehension of the code architecture. However, some models tended to excessively decompose the V0Fitter into individual components:
for instance o4-mini suggested a dedicated TrackFitResultFactory solely for creation of TrackFitResult objects, as well as a TrackHypothesisResolver class with the singular responsibility of mapping V0 to daughter hypotheses.

Ultimately, I chose to adopt several of the suggestions during refactoring, namely a dedicated Config struct as suggested by Claude Sonnet 4, and also track and hypothesis management classes similar to those proposed by GPT-4o.

\paragraph{Metaprompting}
The inconsistent nature of some of the LLMs' refactoring suggestions may also have been caused by my own broad and unspecific prompting, lacking clear requirements.
To address this, I subsequently regularly used the technique of metaprompting \cite{metaprompting}, i.e.\ leveraging LLMs to refine and structure prompts.
This approach is particularly valuable, as LLM response quality has been found to depend significantly on how clearly the objective and its context are specified \cite{prompt-quality}.

One important caveat is worth mentioning: using models from the same family or vendor for both metaprompt generation and prompt execution may introduce bias into the results.
Since similar model architectures could inherently be better at interpreting prompts generated by related models, this setup might lead to artificially inflated performance.
However, based on my observations, this potential bias did not appear to significantly affect the outcomes.

\def\sectitle{Documentation Generation for the V0Fitter Refactor}
\subsubsection%
[\sectitle]
{\sectitle
  \footnote{\repoRef{chats/tree/main/v0fitter/documentation-generation-test}{chats/v0fitter/documentation-generation-test}}
}
As an initial test of agentic AI capabilities, I tasked GitHub Copilot with generating Doxygen documentation \cite{doxygen} for the refactored V0Fitter code, using Copilot's Agent mode in VS Code.

First, I generated a unified set of agent instructions by metaprompting ChatGPT \cite{chatgpt}.
I then repeatedly invoked the GitHub Copilot agent with the same prompt, each time using a different one of the chosen models, and resetting the repository to a clean state%
\footnote{Commit b5d0721 in \repoRef{basf2}{basf2}; fitter header file undocumented at this stage}
before dispatching the request.
In addition to the instruction prompt, the agents were provided with the source files to be edited, a \enquote{doxygen-cheatsheet}%
\footnote{
  \repoRef{chats/blob/main/v0fitter/documentation-generation-test/initial-prompt/doxygen-overview.md}{chats/v0fitter/documentation-generation-test/initial-prompt/doxygen-overview.md}
}, 
and the \emph{Documentation} section from the basf2 coding conventions \cite{basf2-coding-conventions} as context.

However, the information provided might not have been specific enough, seeing as the agents produced inconsistent documentation outputs.

To address this, I reformulated the prompt as a concrete list of requirements, explicitly requiring every class and member to be documented, and directly included the desired Doxygen syntax in the instructions.
Additionally, I modified the prompt context to only include the source files of the refactored version, as well as the original V0Fitter's header file, hoping that the documentation contained within would enhance the model's comprehension of the code logic.

\vspace{\baselineskip}
Reviewing the code generated by the selected models, I made the following observations:

\vspace{-1\baselineskip}
\paragraph{Claude Sonnet 4}
The GitHub Copilot agent using this underlying model for generation produced generally meaningful documentation in both prompt iterations, though it often just rephrased variable or method names.
Notably, however, it was able to correctly infer ambiguous return values (Lst.\ \ref{lst:docgen-sonnet}, 1).

In the second prompt iteration, the added context of the current V0Fitter documentation appears to have enabled the model to infer more about the code logic, such as interpreting the meanings of the different fitter mode values (Lst.\ \ref{lst:docgen-sonnet}, 2).
Additionally, the documentation generated for newly introduced structures without a counterpart in the original V0Fitter was generally reasonable, but at times too vague to determine whether the underlying logic had actually been understood (Lst.\ \ref{lst:docgen-sonnet}, 3).

\begin{lstbox}{%
    \captionof{customlst}{Annotated excerpts from the Claude Sonnet 4 agent diffs illustrating notable edits (from both prompt iterations)}
    \label{lst:docgen-sonnet}
  }
  \import{listings/v0fitter/agent-edits/}{docgen-sonnet.tex}
\end{lstbox}

\paragraph{Gemini 2.5 Pro} also generated relatively precise documentation, but, similarly to Claude Sonnet 4, it tended to simply rephrase the names of symbols, and produced non-descriptive comments in some instances.
For example, it generated virtually the same comment as Claude Sonnet 4 in Listing \ref{lst:docgen-sonnet}, (3).

Additionally, Gemini 2.5 Pro occasionally misinterpreted the meaning of values, e.g.\ the boolean returned by checkInnerHits (Lst.\ \ref{lst:docgen-sonnet}, 1) was interpreted as a detection result by the model.

On the second prompt iteration, it followed the instructions as specified, during the first prompt however, a friend declaration was modified, and a destructor declaration removed, despite being told not to alter any code logic.

\paragraph{GPT-4o}
For the first prompt, the documentation generated was somewhat meaningful, however several symbols were incorrectly interpreted, such as the booleans returned by checkInnerHits or checkSharedInnermostCluster,
and the model failed to document several class members altogether.

Processing of the second prompt consistently failed with the error message: \enquote{Error: Sorry, the response hit the length limit. Please rephrase your prompt.}

\paragraph{o4-mini}
Prompting GitHub Copilot with o4-mini as underlying LLM produced some surprisingly insightful documentation, even for the initial prompt that didn't include any existing documentation as context.
Most notably, the non-trivial underlying logic of the v0FitterMode values, the TrackContainer destructor, as well as the pdgClosest variable was partly inferred from the code (Lst.\ \ref{lst:docgen-o4-mini}).
However, the model left all data members undocumented and removed necessary forward declarations in the header file.

In response to the second prompt, the agent no longer modified any code logic, while maintaining more or less the same documentation quality and adding documentation for some, but not all members.
That being said, the model seems to have misunderstood the instruction to use inline comments for member documentation, using them universally throughout the code.

In hindsight, I should have explicitly specified in the prompt, how non-member documentation should be handled, as this might have prevented the issue described.

\begin{lstbox}{%
    \captionof{customlst}{Excerpts from the o4-mini agent diffs illustrating notable edits in response to the first prompt iteration}
    \label{lst:docgen-o4-mini}
  }
  \import{listings/v0fitter/agent-edits/}{docgen-o4-mini.tex}
\end{lstbox}

\vspace{\baselineskip}
Overall, I found Claude Sonnet 4 to be the most consistent, while o4-mini stood out for its relatively insightful documentation that avoided simply restating declaration names.

\def\sectitle{V0Fitter Optimization Test}
\subsubsection%
[\sectitle]
{\sectitle
  \footnote{\repoRef{chats/tree/main/v0fitter/optimization-test}{chats/v0fitter/optimization-test}}
}
To further test the agentic capabilities of the four tested AI models, I optimistically tasked them with the broad goal of optimizing the V0Fitter's performance.

As a first step, I generated a unified set of instructions by metaprompting Anthropic's Claude Sonnet 3.7 Thinking model%
\footnote{A version of Claude Sonnet 3.7 \cite{claude-sonnet37} configured to use extended reasoning effort},
and set the context to include the original V0Fitter source code.
To ensure consistency and comparability of the testing results, for each of the models, I reverted the repository to the release-09-00-00 commit before dispatching the prompt via the Copilot Agent mode chat, and then left the agents to complete the task autonomously.
I refrained from any further input, except to confirm continuation of execution in case of long runtimes.

\vspace{\baselineskip}
While examining the code produced by the different models, I made several observations:

\vspace{-1\baselineskip}
\paragraph{Claude Sonnet 4} made adjustments that may have a positive impact on performance, though not a significant one.
The changes primarily target computations that are either inexpensive or likely to be optimized by the compiler anyway, for example, caching the size of a vector for use in a loop bound check, or promoting a vector to a class member that is used to store the pointers of the genfit::Track pair.

On the other hand, a modest improvement to code organization was made by introducing the TrackCache struct, which encapsulates frequently accessed values, such as a pointer to the track fit result with mass closest to that of the hypothesis particle, its corresponding genfit::Track representation and PDG code.

The most significant modification made by the model was transforming the GFRaveVertexFactory object into a reusable class member.
This change reduces runtime overhead, as repeated invocations of the encapsulated rave::VertexFactory's wipe method are relatively costly (Fig.\ \ref{fig:vertex-factory}).

Fitting a vertex using the factory's create method already invokes wipe prior to the actual vertex fit taking place, therefore constructing a new factory object for each fit introduces unnecessary overhead, especially since wipe is called again during object destruction.
Based on my observations, the wipe method fully resets the internal state of the vertex factory, making it safe for reuse.
For this reason, I have also made the GFRaveVertexFactory a class member in the refactored V0Fitter implementation.

Ultimately, though, the generated code failed to compile, owing to a minor error in the unique\_ptr declaration of the GFRaveVertexFactory member.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.4\linewidth]{static/profiling/profiling-v0fitter/050e500/vertex-factory.pdf}
  \caption{Call graph segment tracing invocations of the rave::VertexFactory::wipe method; annotated with profiling metrics}\label{fig:vertex-factory}
\end{figure}

\paragraph{Gemini 2.5 Pro}
While the GitHub Copilot agent backed by Gemini 2.5 Pro produced code that compiles successfully, it made significant changes to the code logic, despite explicit instructions not to do so.

The hit removal loop boundary conditions were altered in a manner that deviates entirely from the original implementation, indicating a fundamental misunderstanding of the underlying functionality of the code (Lst.\ \ref{lst:optimize-gemini25pro}).
Additionally, the agent removed several log outputs from the code and introduced caching of genfit::Track retrievals, which unnecessarily avoids calls to the lightweight RecoTrackGenfitAccess::getGenfitTrack interface method.

However, it also implemented a meaningful optimization by adjusting the code to only refit RecoTracks that contain inner hits, since by default, the V0Fitter performs a single refit of tracks without inner hits at the beginning of the hit removal iterations.

Given that the positive impact of this operation on the removal process is unclear and it introduces considerable runtime overhead, both the NewV0Fitter and my refactored version of the V0Fitter have removed this functionality as well.

\begin{lstbox}{%
    \captionof{customlst}{Gemini 2.5 Pro agent edit that significantly modifies the hit removal iteration limit in fitAndStore, replacing the previous fixed limit of 5 with the total number of hits in the RecoTrack pair}
    \label{lst:optimize-gemini25pro}
  }
  \import{listings/v0fitter/agent-edits/}{optimize-gemini25pro.tex}
\end{lstbox}

\paragraph{GPT-4o} made changes that may slightly improve performance, such as adding an unordered\_map to cache the lookup of daughter particle hypotheses for a given V0 hypothesis.
It is doubtful whether this offers any speed advantage over the original implementation, which uses conditional statements to map the four V0 hypotheses to their respective daughter particles.

On the other hand, the agent removed multiple log outputs and comments in the code, and more concerningly, removed key parts of the code altogether:
Essential logic was deleted without any replacement or explanation, such as the statements setting the track's cardinal representation before vertex fitting, and those storing V0 objects \textemdash the main purpose of the module (Lst.\ \ref{lst:optimize-gpt4o}, 1).
Additionally, the entire inner hit removal logic was eliminated (Lst.\ \ref{lst:optimize-gpt4o}, 2), and the parameters used to store the ValidationV0 object were modified, resulting in a compilation failure.

\begin{lstbox}{%
    \captionof{customlst}{
      GPT-4o agent edits removing critical V0Fitter functionality
    }
    \label{lst:optimize-gpt4o}
  }
  \import{listings/v0fitter/agent-edits/}{optimize-gpt4o.tex}
\end{lstbox}

\paragraph{o4-mini}
Prompting the GitHub Copilot agent with o4-mini selected as underlying LLM produced only a few, but relatively reasonable changes, and the modified code compiled successfully.

The agent converted the GFRaveVertexFactory and TrackFitter objects into class members, along with the vector containing the pair of genfit::Track pointers that are passed to the vertex factory for fitting.
While I am confident that the first modification constitutes a meaningful and computationally safe optimization, I am uncertain about the effects of making the TrackFitter object a class member: seeing as it has a resetFitter method, it may maintain some internal state.
Additionally, profiling data indicates that TrackFitter construction and destruction accounts for only about \qty{0.03}{\percent} of total instructions, so eliminated overhead is negligible.

\vspace{\baselineskip}
Overall, although the AI agents' performance on this optimization task was underwhelming, it was not particularly surprising. 
It was to be expected that LLMs would face considerable difficulties in generating code that integrates effectively into basf2's extensive codebase and complex logic.

\subsubsection{Use of AI during coding}
\paragraph{ChatGPT} was the AI tool I relied on most during the V0Fitter refactoring, primarily for C++-related questions, but also for queries involving Linux utilities and general development issues.
While the value and quality of responses varied, I found it to be very helpful overall.

Listing \ref{lst:chatgpt-reference-invalidation} shows an example of a particularly helpful response I received, while Listing \ref{lst:chatgpt-static-reference-init} illustrates one of the key limitations of LLMs: their tendency to generate plausible but incorrect output with apparent confidence.

\begin{lstbox}{%
    \captionof{customlst}{
      ChatGPT output that helped me recognize reference invalidation due to vector reallocation as the cause of observed segmentation faults%
      \footnotemark
    }
    \label{lst:chatgpt-reference-invalidation}
  }
  \import{listings/v0fitter/chats/}{chatgpt-reference-invalidation.tex}
\end{lstbox}%
\footnotetext{\repoRef{chats/blob/main/v0fitter/questions/chatgpt/C++-Reference-Invalidation.md}{chats/v0fitter/questions/chatgpt/C++-Reference-Invalidation.md}}

\begin{lstbox}{%
    \captionof{customlst}{
      ChatGPT recommending to initialize a reference\_wrapper by dereferencing a nullptr%
      \footnotemark
    }\label{lst:chatgpt-static-reference-init}
  }
  \import{listings/v0fitter/chats/}{chatgpt-static-reference-init.tex}
\end{lstbox}%
\footnotetext{\repoRef{chats/blob/main/v0fitter/questions/chatgpt/Static-reference-initialization.md}{chats/v0fitter/questions/chatgpt/Static-reference-initialization.md}}

\paragraph{Copilot Ask Mode and Code Completions}

During the V0Fitter refactoring process, I occasionally used the Ask mode of GitHub Copilot Chat, primarily querying Claude Sonnet 4 and Gemini 2.5 Pro, as benchmarks indicated these models were best-suited for programming-related tasks (see Sec.\ \ref{sec:model-selection}).
However, I disabled Copilot's automatic code completion feature early on in development, as the suggestions proved largely unhelpful and disruptive to the workflow (cf.\ Fig.\ \ref{fig:copilot-ui}, Left).

When responding to questions related to the refactoring work, as well as the broader basf2 codebase, Copilot demonstrated a profound comprehension of the indexed repository structure.
It typically answered specific questions accurately when referencing relevant files, or even the entire codebase as context.

For instance, GitHub Copilot successfully identified a bug in my refactored code (Lst.\ \ref{lst:copilot-bug-find}).

However, the models sometimes presented incorrect information with high certainty, similar to the reliability issues discussed earlier (Listing \ref{lst:copilot-useInFit}).

Overall though, Copilot's Ask mode proved very valuable for codebase exploration, serving as both an intelligent search tool and a documentation system that could synthesize information from multiple files.
While useful as an initial resource, I found it necessary to independently verify important technical details to ensure correctness.

\begin{lstbox}{%
    \captionof{customlst}{
      GitHub Copilot detects a bug caused by copy-pasting a statement without fully updating its content.%
      \footnotemark\\
      \textbf{Note:} \#file is used to add a file to the chat context.
    }\label{lst:copilot-bug-find}
  }
  \import{listings/v0fitter/chats/}{copilot-bug-find.tex}
\end{lstbox}%
\footnotetext{\repoRef{chats/blob/main/v0fitter/questions/copilot/bug-find.md}{chats/v0fitter/questions/copilot/bug-find.md}}

\begin{lstbox}{%
    \captionof{customlst}{
      GitHub Copilot incorrectly suggests that addHitsFromRecoTrack copies the useInFit attribute of RecoHitInformation objects%
      \footnotemark
    }\label{lst:copilot-useInFit}
  }
  \import{listings/v0fitter/chats/}{copilot-useInFit.tex}
\end{lstbox}%
\footnotetext{\repoRef{chats/blob/main/v0fitter/questions/copilot/useInFit-copy.md}{chats/v0fitter/questions/copilot/useInFit-copy.md}}
