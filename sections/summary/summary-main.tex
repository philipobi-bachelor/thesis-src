At the beginning of my research, I did not use AI tools frequently and was rather skeptical about their capabilities.
Through the work on this thesis, I became significantly more familiar with LLMs and now have a better understanding of both their strengths and shortcomings.

Drawing from my experiences throughout the research process, I found that LLMs are overall very helpful for software optimization tasks.

\vspace{\baselineskip}
For highly complex codebases such as basf2, the tests I performed showed mixed results.
In my testing, LLMs appeared less suited for code generation tasks, at least with the models I evaluated.
It is possible that more capable models could produce acceptable code for such complex systems.
However, I found that LLMs proved very helpful for code analysis and understanding tasks.
They excelled at codebase exploration, synthesizing and summarizing information from various files, explaining questions related to the code, and finding bugs.

\vspace{\baselineskip}
For medium to low complexity coding tasks, my test results for generic code optimization indicated different performance patterns.
I observed that LLMs are capable of generating functional and usable code, though the quality varied between models and specific examples.
From my testing, I noticed that the more common the code pattern, the better the generated code generally was.

\vspace{\baselineskip}
Beyond the formal testing scenarios, I benefited significantly from querying LLMs, mainly ChatGPT, during the development of test infrastructure and especially the V0Fitter refactoring process.
LLMs provided valuable assistance with containerization-related topics for benchmarking the generic code optimization examples and for implementing my chat archiving tool.
I also found that LLM responses were particularly useful for addressing general Python and Linux-related questions.

\vspace{\baselineskip}
Overall, the main benefit of AI usage that I experienced was a significantly accelerated development speed:
I could ask questions specific to my use case and get meaningful results, and
my questions did not have to be perfectly formulated because LLMs can understand context and interpret vague or imprecise queries, which I found to be a significant advantage over conventional search engines.
The responses to broad queries often pointed me in the right direction for more detailed research.

\vspace{\baselineskip}
Among the models I compared, I had the best experience with Claude Sonnet 4, which consistently generated high-quality responses and, to some extent, code.

I also used AI extensively during the writing of my thesis, where I again had good experiences with Claude Sonnet 4.
I accessed it primarily via Anthropic's chat website \cite{claude-online} and received overall better responses than from ChatGPT.

My use cases for AI during the thesis writing phase were mainly help with English formulations,
searching through my LaTeX code to identify typographical and grammatical errors,
detecting potential factual inconsistencies,
help with implementing certain LaTeX functionality,
and debugging LaTeX errors.
Interestingly, I found that debugging LaTeX errors was almost as complex as debugging the code during the research phase of the thesis.

\vspace{\baselineskip}
One factor that I perhaps should have paid more attention to during my tests is prompt quality and prompt engineering.
Literature sources indicate that prompt composition has a strong impact on response quality \cite{prompt-quality}, which I also observed during my tests.
I believe the AI models might have performed better on some of my tests if the prompts had been more carefully constructed.
However, I think that having to carefully compose prompts for a model to produce acceptable results reduces many of the benefits that LLMs offer,
which are considerably rooted in the ability to use natural language queries to interact with the system.

\vspace{\baselineskip}
While LLMs offer many advantages for software development and optimization tasks, they also have notable limitations and disadvantages.
First, as observed from some responses throughout the course of this thesis, LLMs do make mistakes and can confidently provide incorrect answers.
Also, having entire codebases generated by AI can lead to code that includes vulnerabilities, has inconsistent coding conventions, and is overall hard to maintain.
Another concern I have about LLMs is their high environmental impact, mainly during training but also during inference.

Another issue that I consider significant is that AI is increasingly replacing the use of knowledge bases and forums, such as Stack Overflow \cite{stackoverflow-decline}.
I find this problematic because Stack Overflow constitutes a transparent and human-readable knowledge base, which is likely where much of AI's software development knowledge comes from.
In contrast, AI's knowledge is encoded in its parameters, and this information is not readily accessible due to both the closed-source nature of many popular LLMs and the fact that information is spread across billions of learned parameters with no way to extract it.
As more people rely on LLMs for software development support, I believe that less knowledge will be documented in forums like Stack Overflow.
Additionally, LLMs generally do not keep track of helpful responses, whereas on Stack Overflow, posts with many upvotes can generally be considered correct or helpful to many people.
I think this might lead to a loss of publicly available knowledge in the long term.
